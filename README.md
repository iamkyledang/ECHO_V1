# ECHO_V1 — Offline Subtitle Generator

ECHO_V1 is an offline subtitle generator that combines Voice Activity Detection (VAD), speaker diarization, and speech-to-text to create SRT subtitle files from video content. It is designed to run locally for privacy and to produce time-aligned, high-quality subtitles.

[Demo video](https://drive.google.com/file/d/1AYn8jPrrvCwohab1q418Y8J2un8wrq2U/view?usp=sharing)

---

s
---

## Highlights

- Offline subtitle generation (SRT)
- VAD-based segmentation and optional VAD model training
- Integration points for speech recognition, alignment, and diarization
- GUI front-end for easy use

---

## Repository structure

- `assets/` — icons and GUI assets
- `source/` — main application code and GUI (`main.py`, `transcriber.py`)
- `scripts/` — Windows install / helper batch scripts (installers and environment helpers)
- `training_code/` — training and evaluation scripts for VAD and subtitle evaluation
  - `prepare_voxconverse.py` (data prep helper — requires your dataset)
  - `standalone_train_vad.py` (train VAD model)
  - `standalone_inference.py` (example inference using trained model)
  - `evaluate_vad_model.py` (model evaluation)
  - `srt_evaluation.py` (subtitle quality evaluation)
- `model.pt` — example/trained VAD model (may be generated by training)
- `requirements.txt` — Python dependencies

---

## Quickstart — Installation

1. Install Python 3.9+.
2. Create and activate a virtual environment (recommended):

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

3. Install dependencies:

```powershell
pip install -r requirements.txt
```

---

## Usage

Run the GUI application:

```powershell
python source/main.py
```

Training and inference (optional):

```powershell
python training_code/prepare_voxconverse.py   # prepare your dataset (you must supply dataset)
python training_code/standalone_train_vad.py  # train VAD -> produces model.pt
python training_code/standalone_inference.py  # example inference using trained model
```

Evaluate model or SRT output:

```powershell
python training_code/evaluate_vad_model.py
python training_code/srt_evaluation.py
```


---

## How it works 

- VAD segments audio into speech/non-speech intervals.
- Speech segments are passed to a speech-to-text component for transcription.
- Pytorch based alignment tool is used for fine-grained timing.
- Optional diarization assigns speaker labels when enabled.
- Processed segments are formatted into SRT subtitle files.
---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE.txt) file for details.

---

## Author

- **Name:** Kyle Dang
- **Contact:** dangmauanhquan@gmail.com

---

## Academic Project & Report

- **Course:** Programming Integration Project — Ho Chi Minh University of Technology (HCMUT)
- **Assessment:** Graded 10/10 for this submission
- **Report:** A PDF project report has been attached in this repository.
---

## Contributing

- Open an issue to discuss changes or submit a pull request with improvements. If you add dataset preparation or sample test data, mention licensing for those files.

---

